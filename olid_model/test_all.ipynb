{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c02f7d-f22e-408c-a36f-e0256dbd9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_all_tasks.ipynb\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37778ddd-1f36-4f2e-a90b-82654660766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Forcer l'exécution sur CPU ===\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# === Task A ===\n",
    "model_A = AutoModelForSequenceClassification.from_pretrained(\"./final_models/best_model_A_roberta-base\")\n",
    "tokenizer_A = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model_A.to(device)\n",
    "\n",
    "# === Task B ===\n",
    "model_B = AutoModelForSequenceClassification.from_pretrained(\"./final_models/best_model_B_hateBERT\")\n",
    "tokenizer_B = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "model_B.to(device)\n",
    "\n",
    "# === Task C ===\n",
    "model_C = AutoModelForSequenceClassification.from_pretrained(\"./final_models/best_model_C_hateBERT\")\n",
    "tokenizer_C = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "model_C.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e264bd48-5a7e-4a6d-8faf-e63522ed964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Texte à prédire ===\n",
    "df = pd.read_csv(\"../datasets/trial-data/offenseval-trial.txt\", sep=\"\\t\", header=None)\n",
    "df.columns = [\"text\", \"label_A_gold\", \"label_B_gold\", \"label_C_gold\"]\n",
    "tweets = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f12e253a-94b9-4a38-afe1-b731251ed11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts, model, tokenizer, max_length=128):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    # Envoyer inputs sur le même device que le modèle\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    return torch.argmax(logits, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f6c4f8-589f-428f-a5bb-064881057a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Étape 1 : prédiction Task A ===\n",
    "y_pred_A = predict(tweets, model_A, tokenizer_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "305133bb-aefa-48cb-8966-25cf700d78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Étape 2 : prédiction Task B sur tweets OFF ===\n",
    "off_mask = (y_pred_A == 1)\n",
    "tweets_B = [t for i, t in enumerate(tweets) if off_mask[i]]\n",
    "y_pred_B_partial = predict(tweets_B, model_B, tokenizer_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb805056-43f1-423c-864b-244ec2365c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Étape 3 : prédiction Task C sur tweets TIN ===\n",
    "tin_mask = (y_pred_B_partial == 1)\n",
    "tweets_C = [t for i, t in enumerate(tweets_B) if tin_mask[i]]\n",
    "y_pred_C_partial = predict(tweets_C, model_C, tokenizer_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53e1c9de-47a2-4ebb-a3be-12413a4a067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Reconstruction du DataFrame avec les prédictions ===\n",
    "pred_A = [\"OFF\" if x == 1 else \"NOT\" for x in y_pred_A]\n",
    "pred_B, pred_C = [\"NULL\"] * len(tweets), [\"NULL\"] * len(tweets)\n",
    "\n",
    "b_idx = 0\n",
    "for i, is_off in enumerate(off_mask):\n",
    "    if is_off:\n",
    "        pred_B[i] = \"TIN\" if y_pred_B_partial[b_idx] == 1 else \"UNT\"\n",
    "        b_idx += 1\n",
    "\n",
    "c_idx = 0\n",
    "for i, is_off in enumerate(off_mask):\n",
    "    if is_off and pred_B[i] == \"TIN\":\n",
    "        pred_C[i] = [\"IND\", \"GRP\", \"OTH\"][y_pred_C_partial[c_idx]]\n",
    "        c_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7789d497-5687-4a63-9307-94e251b76b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text pred_A pred_B pred_C\n",
      "0  @BreitbartNews OK Shannon, YOU tell the vetera...    NOT   NULL   NULL\n",
      "1  @LeftyGlenn @jaredeker @BookUniverse @hashtagz...    NOT   NULL   NULL\n",
      "2  Hot Mom Sucks Off Step Son In Shower 8 min htt...    OFF    TIN    IND\n",
      "3  bro these are some cute butt plugs I’m trying ...    OFF    TIN    IND\n",
      "4  Arizona Supreme Court strikes down state legis...    NOT   NULL   NULL\n",
      "5  Arguing gun control is wrong of me whoever has...    NOT   NULL   NULL\n",
      "6  Doctors’ interest in medical marijuana far out...    NOT   NULL   NULL\n",
      "7  A must-read and a must-share for all your frie...    NOT   NULL   NULL\n",
      "8  @Jo2timess Now that’s the dumbest shit I have ...    OFF    UNT   NULL\n",
      "9  Agreed! When all of this drama was unfolding a...    OFF    TIN    IND\n"
     ]
    }
   ],
   "source": [
    "# === Résultat final ===\n",
    "df[\"pred_A\"] = pred_A\n",
    "df[\"pred_B\"] = pred_B\n",
    "df[\"pred_C\"] = pred_C\n",
    "\n",
    "print(df[[\"text\", \"pred_A\", \"pred_B\", \"pred_C\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a78ff3ef-7ad5-42db-8446-60cbb0576a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Task A ===\n",
      "Accuracy: 0.859375\n",
      "F1-score: 0.816267942583732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.93      0.88      0.91       243\n",
      "         OFF       0.68      0.78      0.73        77\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.80      0.83      0.82       320\n",
      "weighted avg       0.87      0.86      0.86       320\n",
      "\n",
      "\n",
      "=== Task B ===\n",
      "Accuracy: 0.6140350877192983\n",
      "F1-score: 0.5991048593350383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         UNT       0.92      0.36      0.52        33\n",
      "         TIN       0.52      0.96      0.68        24\n",
      "\n",
      "    accuracy                           0.61        57\n",
      "   macro avg       0.72      0.66      0.60        57\n",
      "weighted avg       0.75      0.61      0.59        57\n",
      "\n",
      "\n",
      "=== Task C ===\n",
      "Accuracy: 0.7083333333333334\n",
      "F1-score: 0.391812865497076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         IND       0.84      0.84      0.84        19\n",
      "         GRP       0.50      0.25      0.33         4\n",
      "         OTH       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.45      0.36      0.39        24\n",
      "weighted avg       0.75      0.71      0.72        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Convertir labels gold en formats compatibles\n",
    "gold_A = [1 if label == \"OFF\" else 0 for label in df[\"label_A_gold\"]]\n",
    "gold_B = [1 if label == \"TIN\" else 0 if label == \"UNT\" else -1 for label in df[\"label_B_gold\"]]\n",
    "gold_C = [\"IND\", \"GRP\", \"OTH\"]\n",
    "gold_C = [gold_C.index(label) if label in gold_C else -1 for label in df[\"label_C_gold\"]]\n",
    "\n",
    "# Eval Task A\n",
    "print(\"\\n=== Task A ===\")\n",
    "print(\"Accuracy:\", accuracy_score(gold_A, y_pred_A))\n",
    "print(\"F1-score:\", f1_score(gold_A, y_pred_A, average=\"macro\"))\n",
    "print(classification_report(gold_A, y_pred_A, target_names=[\"NOT\", \"OFF\"]))\n",
    "\n",
    "# Eval Task B\n",
    "gold_B_eval = [g for i, g in enumerate(gold_B) if off_mask[i] and g != -1]\n",
    "pred_B_eval = [1 if b == \"TIN\" else 0 for i, b in enumerate(pred_B) if off_mask[i] and gold_B[i] != -1]\n",
    "\n",
    "print(\"\\n=== Task B ===\")\n",
    "print(\"Accuracy:\", accuracy_score(gold_B_eval, pred_B_eval))\n",
    "print(\"F1-score:\", f1_score(gold_B_eval, pred_B_eval, average=\"macro\"))\n",
    "print(classification_report(gold_B_eval, pred_B_eval, target_names=[\"UNT\", \"TIN\"]))\n",
    "\n",
    "# Eval Task C\n",
    "gold_C_eval = [g for i, g in enumerate(gold_C) if off_mask[i] and pred_B[i] == \"TIN\" and g != -1]\n",
    "pred_C_eval = [ [\"IND\", \"GRP\", \"OTH\"].index(c) for i, c in enumerate(pred_C) if off_mask[i] and pred_B[i] == \"TIN\" and gold_C[i] != -1 ]\n",
    "\n",
    "print(\"\\n=== Task C ===\")\n",
    "print(\"Accuracy:\", accuracy_score(gold_C_eval, pred_C_eval))\n",
    "print(\"F1-score:\", f1_score(gold_C_eval, pred_C_eval, average=\"macro\"))\n",
    "print(classification_report(gold_C_eval, pred_C_eval, target_names=[\"IND\", \"GRP\", \"OTH\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb344f3c-0169-4f2f-befe-fcffee07bb9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNOT       0.93      0.88      0.90       243\u001b[39m\n                                                ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# First : Same Roberta-base for all\n",
    "#-> good for A\n",
    "=== Task A ===\n",
    "Accuracy: 0.859375\n",
    "F1-score: 0.8190932046885011\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         NOT       0.93      0.88      0.90       243\n",
    "         OFF       0.67      0.81      0.73        77\n",
    "\n",
    "    accuracy                           0.86       320\n",
    "   macro avg       0.80      0.84      0.82       320\n",
    "weighted avg       0.87      0.86      0.86       320\n",
    "\n",
    "\n",
    "=== Task B ===\n",
    "Accuracy: 0.4067796610169492\n",
    "F1-score: 0.2891566265060241\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         UNT       0.00      0.00      0.00        35\n",
    "         TIN       0.41      1.00      0.58        24\n",
    "\n",
    "    accuracy                           0.41        59\n",
    "   macro avg       0.20      0.50      0.29        59\n",
    "weighted avg       0.17      0.41      0.24        59\n",
    "\n",
    "\n",
    "=== Task C ===\n",
    "Accuracy: 0.8076923076923077\n",
    "F1-score: 0.4682539682539682\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       0.90      0.90      0.90        21\n",
    "         GRP       0.40      0.67      0.50         3\n",
    "         OTH       0.00      0.00      0.00         2\n",
    "\n",
    "    accuracy                           0.81        26\n",
    "   macro avg       0.43      0.52      0.47        26\n",
    "weighted avg       0.78      0.81      0.79        26\n",
    "\n",
    "\n",
    "# Second : Bertweet on A, HateBert on B and C\n",
    "=== Task A ===\n",
    "Accuracy: 0.85625\n",
    "F1-score: 0.8114367698298832\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         NOT       0.92      0.88      0.90       243\n",
    "         OFF       0.68      0.77      0.72        77\n",
    "\n",
    "    accuracy                           0.86       320\n",
    "   macro avg       0.80      0.83      0.81       320\n",
    "weighted avg       0.86      0.86      0.86       320\n",
    "\n",
    "\n",
    "=== Task B ===\n",
    "Accuracy: 0.5357142857142857\n",
    "F1-score: 0.5133689839572193\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         UNT       1.00      0.26      0.41        35\n",
    "         TIN       0.45      1.00      0.62        21\n",
    "\n",
    "    accuracy                           0.54        56\n",
    "   macro avg       0.72      0.63      0.51        56\n",
    "weighted avg       0.79      0.54      0.49        56\n",
    "\n",
    "\n",
    "=== Task C ===\n",
    "Accuracy: 0.8571428571428571\n",
    "F1-score: 0.47297297297297297\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       0.85      1.00      0.92        17\n",
    "         GRP       1.00      0.33      0.50         3\n",
    "         OTH       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.86        21\n",
    "   macro avg       0.62      0.44      0.47        21\n",
    "weighted avg       0.83      0.86      0.82        21\n",
    "\n",
    "\n",
    "# Third : Bertweet on A, HateBert_finetune on B and C\n",
    "=== Task A ===\n",
    "Accuracy: 0.85625\n",
    "F1-score: 0.8114367698298832\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         NOT       0.92      0.88      0.90       243\n",
    "         OFF       0.68      0.77      0.72        77\n",
    "\n",
    "    accuracy                           0.86       320\n",
    "   macro avg       0.80      0.83      0.81       320\n",
    "weighted avg       0.86      0.86      0.86       320\n",
    "\n",
    "\n",
    "=== Task B ===\n",
    "Accuracy: 0.625\n",
    "F1-score: 0.6190476190476191\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         UNT       1.00      0.40      0.57        35\n",
    "         TIN       0.50      1.00      0.67        21\n",
    "\n",
    "    accuracy                           0.62        56\n",
    "   macro avg       0.75      0.70      0.62        56\n",
    "weighted avg       0.81      0.62      0.61        56\n",
    "\n",
    "\n",
    "=== Task C ===\n",
    "Accuracy: 0.8095238095238095\n",
    "F1-score: 0.4343434343434343\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       1.00      0.94      0.97        17\n",
    "         GRP       0.33      0.33      0.33         3\n",
    "         OTH       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.81        21\n",
    "   macro avg       0.44      0.42      0.43        21\n",
    "weighted avg       0.86      0.81      0.83        21\n",
    "\n",
    "# Fourth : Bertweet on A, HateBert_finetune with weighted loss on B and C\n",
    "# -> good for B\n",
    "=== Task A ===\n",
    "Accuracy: 0.85625\n",
    "F1-score: 0.8114367698298832\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         NOT       0.92      0.88      0.90       243\n",
    "         OFF       0.68      0.77      0.72        77\n",
    "\n",
    "    accuracy                           0.86       320\n",
    "   macro avg       0.80      0.83      0.81       320\n",
    "weighted avg       0.86      0.86      0.86       320\n",
    "\n",
    "\n",
    "=== Task B ===\n",
    "Accuracy: 0.7678571428571429\n",
    "F1-score: 0.7677830940988836\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         UNT       1.00      0.63      0.77        35\n",
    "         TIN       0.62      1.00      0.76        21\n",
    "\n",
    "    accuracy                           0.77        56\n",
    "   macro avg       0.81      0.81      0.77        56\n",
    "weighted avg       0.86      0.77      0.77        56\n",
    "\n",
    "\n",
    "=== Task C ===\n",
    "Accuracy: 0.6666666666666666\n",
    "F1-score: 0.2828282828282828\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       0.88      0.82      0.85        17\n",
    "         GRP       0.00      0.00      0.00         3\n",
    "         OTH       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.67        21\n",
    "   macro avg       0.29      0.27      0.28        21\n",
    "weighted avg       0.71      0.67      0.69        21\n",
    "\n",
    "# Fifth : C on hateBert without some advances : \n",
    "=== Task C ===\n",
    "Accuracy: 0.6666666666666666\n",
    "F1-score: 0.4091954022988506\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       1.00      0.71      0.83        17\n",
    "         GRP       0.29      0.67      0.40         3\n",
    "         OTH       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.67        21\n",
    "   macro avg       0.43      0.46      0.41        21\n",
    "weighted avg       0.85      0.67      0.73        21\n",
    "\n",
    "#Sixth : C with bert base uncased : \n",
    "=== Task C ===\n",
    "Accuracy: 0.6190476190476191\n",
    "F1-score: 0.35000000000000003\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         IND       0.92      0.71      0.80        17\n",
    "         GRP       0.20      0.33      0.25         3\n",
    "         OTH       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.62        21\n",
    "   macro avg       0.37      0.35      0.35        21\n",
    "weighted avg       0.78      0.62      0.68        21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b85f3-076e-40e5-bd6d-3c608e3af612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd0684-b976-4774-9b1b-bee192a4ad99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepl)",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
