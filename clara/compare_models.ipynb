{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from DataReader import DataReader\n",
    "from Preprocessor import Preprocessor\n",
    "from Vectorizer import Vectorizer\n",
    "from DeepLearning import DeepLearner\n",
    "from Classifier import Classifier\n",
    "\n",
    "import importlib\n",
    "import Vectorizer\n",
    "importlib.reload(Vectorizer)\n",
    "from Vectorizer import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Evaluation Function\n",
    "def evaluate_model(model, x, y_true, model_type='sklearn', class_num=2):\n",
    "    if model_type == 'sklearn':\n",
    "        y_pred = model.predict(x)\n",
    "    elif model_type == 'pytorch':\n",
    "        y_pred = model.predict(x)  # Must be implemented in DeepLearner\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='weighted'),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "# üß™ Function to load models and evaluate on a subtask\n",
    "def evaluate_subtask(letter, class_num):\n",
    "    print(f\"\\nüîç Evaluating Subtask {letter}\")\n",
    "    dr = DataReader(f'../datasets/training-v1/offenseval-training-v1.tsv', letter)\n",
    "    data, labels = dr.get_labelled_data()\n",
    "    data, labels = dr.shuffle(data, labels, 'random')\n",
    "    tr_data, tst_data, y_tr, y_tst = train_test_split(data, labels, test_size=0.3)\n",
    "\n",
    "    preprocessor = Preprocessor(('remove_stopwords', 'lemmatize'))\n",
    "    vectorizer = Vectorizer('count')\n",
    "    tst_clean = preprocessor.clean(tst_data)\n",
    "    x_tst_vec = vectorizer.vectorize(tst_clean)\n",
    "\n",
    "    model_names = ['RandomForest', 'LogisticRegression', 'NaiveBayes', 'KNN', 'SVC', 'LSTM', 'CNN']\n",
    "    results = {}\n",
    "\n",
    "    for i, name in enumerate(model_names[:-2]):\n",
    "        model = joblib.load(f\"../saved_models/subtask{letter}_model_{i}.joblib\")\n",
    "        vectorizer = joblib.load(f\"../saved_models/subtask{letter}_vectorizer_{i}.joblib\")\n",
    "        \n",
    "        preprocessor = Preprocessor(('remove_stopwords', 'lemmatize'))  # Ou la bonne config, si tu la sauvegardes\n",
    "        tst_clean = preprocessor.clean(tst_data)\n",
    "        x_tst_vec = vectorizer.vectorize(tst_clean)\n",
    "\n",
    "        results[name] = evaluate_model(model, x_tst_vec, y_tst, model_type='sklearn')\n",
    "\n",
    "    # LSTM\n",
    "    lstm = DeepLearner(tr_data, y_tr, vocab_length=vectorizer.vocab_length, model_type='LSTM')\n",
    "    lstm.load(f\"../saved_models/subtask{letter}_lstm.pth\")\n",
    "    results['LSTM'] = evaluate_model(lstm, tst_clean, y_tst, model_type='pytorch')\n",
    "\n",
    "    # CNN\n",
    "    cnn = DeepLearner(tr_data, y_tr, vocab_length=vectorizer.vocab_length, model_type='CNN')\n",
    "    cnn.load(f\"../saved_models/subtask{letter}_cnn.pth\")\n",
    "    results['CNN'] = evaluate_model(cnn, tst_clean, y_tst, model_type='pytorch')\n",
    "\n",
    "    return model_names, results\n",
    "\n",
    "# üìä Plotting function\n",
    "def plot_metric(results_dict, metric, subtask, model_names):\n",
    "    values = [results_dict[model][metric] for model in model_names]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(model_names, values, color='mediumseagreen')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.title(f\"{metric.capitalize()} per Model ‚Äì Subtask {subtask}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating Subtask A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Data: 13241it [00:00, 275761.84it/s]\n",
      "Tokenization: 3972it [00:00, 6276.16it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 74539.38it/s]1,  1.58it/s]\n",
      "Lemmatization: 3972it [00:02, 1940.85it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Tokenization: 3972it [00:00, 6395.83it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 76786.25it/s]1,  1.61it/s]\n",
      "Lemmatization: 3972it [00:02, 1858.70it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.07it/s]\n",
      "Tokenization: 3972it [00:00, 6440.92it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 75271.54it/s]1,  1.62it/s]\n",
      "Lemmatization: 3972it [00:02, 1942.34it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.10it/s]\n",
      "Tokenization: 3972it [00:00, 6313.23it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 75467.60it/s]1,  1.59it/s]\n",
      "Lemmatization: 3972it [00:02, 1913.99it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Tokenization: 3972it [00:00, 6241.64it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 75003.15it/s]1,  1.57it/s]\n",
      "Lemmatization: 3972it [00:02, 1916.26it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.08it/s]\n",
      "Tokenization: 3972it [00:00, 6645.62it/s]0<?, ?it/s]\n",
      "Stopwords Removal: 3972it [00:00, 77798.52it/s]1,  1.67it/s]\n",
      "Lemmatization: 3972it [00:02, 1982.40it/s]\n",
      "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Vectorizer' object has no attribute 'embedding_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-790776936bc7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ‚úÖ Evaluate all subtasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_subtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_subtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_subtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-95e923af4f1e>\u001b[0m in \u001b[0;36mevaluate_subtask\u001b[0;34m(letter, class_num)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'remove_stopwords'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lemmatize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ou la bonne config, si tu la sauvegardes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtst_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx_tst_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tst_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sklearn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA2/DeepLearning/Projet/DeepL-Breakers/Vectorizer.py\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mvectorize_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectorize_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.type} is not an available function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA2/DeepLearning/Projet/DeepL-Breakers/Vectorizer.py\u001b[0m in \u001b[0;36mglove\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'word2vec.model'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n‚úÖ Loading Word2Vec Embeddings from file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word2vec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Vectorizer' object has no attribute 'embedding_dir'"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Evaluate all subtasks\n",
    "model_names, results_A = evaluate_subtask('A', 2)\n",
    "_, results_B = evaluate_subtask('B', 2)\n",
    "_, results_C = evaluate_subtask('C', 3)\n",
    "\n",
    "# üìà Plot everything\n",
    "for metric in ['accuracy', 'f1', 'precision', 'recall']:\n",
    "    plot_metric(results_A, metric, 'A', model_names)\n",
    "    plot_metric(results_B, metric, 'B', model_names)\n",
    "    plot_metric(results_C, metric, 'C', model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def results_to_df(results_dict, subtask):\n",
    "    df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    df['model'] = df.index\n",
    "    df['subtask'] = subtask\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df_A = results_to_df(results_A, 'A')\n",
    "df_B = results_to_df(results_B, 'B')\n",
    "df_C = results_to_df(results_C, 'C')\n",
    "df_all = pd.concat([df_A, df_B, df_C])\n",
    "df_all.to_csv(\"compare_models_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offenseval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
